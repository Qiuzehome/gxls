import datetime
import json
import requests
import asyncio
from google_sheets import write_google_sheets
from form_checker import load_url
from config import URL_GROUPS, API_URL
from robot import Robot

robot = Robot()

# å…¨å±€ç»Ÿè®¡æ”¶é›†å™¨
WORKSHEET_STATS = {}


def send_summary_report():
    """å‘é€å·¥ä½œè¡¨æ±‡æ€»æŠ¥å‘Š"""
    if not WORKSHEET_STATS:
        robot.send_text("ğŸ“Š ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œä½†æ²¡æœ‰ç»Ÿè®¡æ•°æ®")
        return

    # æ„å»ºæ±‡æ€»æŠ¥å‘Š
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    report_lines = [
        f"ğŸ“Š ä»»åŠ¡æ‰§è¡Œæ±‡æ€»æŠ¥å‘Š",
        f"ğŸ• å®Œæˆæ—¶é—´: {current_time}",
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
    ]

    total_target = 0
    total_actual = 0

    # æŒ‰ç…§æ‰§è¡Œé¡ºåºæ˜¾ç¤ºç»Ÿè®¡
    sequence = ["p0", "00", "p1"]
    for ws_name in sequence:
        if ws_name in WORKSHEET_STATS:
            stats = WORKSHEET_STATS[ws_name]
            total_target += stats["target_results"]
            total_actual += stats["actual_results"]

            report_lines.append(f"ğŸ“‹ å·¥ä½œè¡¨ {ws_name}:")
            report_lines.append(
                f"   ç›®æ ‡: {stats['target_results']} | å®é™…: {stats['actual_results']}"
            )
            report_lines.append(
                f"   å®Œæˆåº¦: {stats['completion_rate']}% | {stats['status']}"
            )
            report_lines.append(f"   æ‰¹æ¬¡æ•°: {stats['total_batches']}")
            report_lines.append("")

    # æ€»ä½“ç»Ÿè®¡
    overall_rate = (
        round((total_actual / total_target) * 100, 1) if total_target > 0 else 0
    )
    report_lines.extend(
        [
            f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:",
            f"   æ€»ç›®æ ‡: {total_target} | æ€»å®é™…: {total_actual}",
            f"   æ€»å®Œæˆåº¦: {overall_rate}%",
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            f"âœ… æ‰€æœ‰å·¥ä½œè¡¨å¤„ç†å®Œæˆï¼Œè¯·æŸ¥çœ‹ https://docs.google.com/spreadsheets/d/1-WdCcC3JA2cyk6Q1gem7a2gkyDJ5RJM_esFJr724OPI/edit?gid=2015433169#gid=2015433169",
        ]
    )

    # å‘é€æŠ¥å‘Š
    report_text = "\n".join(report_lines)
    robot.send_text(report_text)

    # æ¸…ç©ºç»Ÿè®¡æ•°æ®ï¼Œä¸ºä¸‹æ¬¡è¿è¡Œåšå‡†å¤‡
    WORKSHEET_STATS.clear()


def parse_data(urls_data):
    """
    è§£æURLæ•°æ®ï¼Œæ”¯æŒå­—ç¬¦ä¸²URLæˆ–åŒ…å«hrefå’Œparamçš„å­—å…¸
    :param urls_data: URLåˆ—è¡¨ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨æˆ–å­—å…¸åˆ—è¡¨
    :return: æ ¼å¼åŒ–çš„è¡Œæ•°æ®ï¼ŒåŒ¹é…Google Sheetsè¡¨å¤´ ["href", "param", "æ—¥æœŸ", "è´Ÿè´£äºº", "çŠ¶æ€"]
    """
    print(f"è§£ææ•°æ®: {urls_data}")
    rows = []
    today = datetime.datetime.now().strftime("%Y-%m-%d")

    for item in urls_data:
        if isinstance(item, str):
            # å…¼å®¹æ—§æ ¼å¼ï¼šçº¯URLå­—ç¬¦ä¸²
            rows.append([item, "", today, "", ""])
        elif isinstance(item, dict):
            # æ–°æ ¼å¼ï¼šåŒ…å«hrefå’Œparamçš„å­—å…¸
            href = item.get("href", "")
            param = item.get("param", "")
            # æˆªå–paramçš„ç¬¬ä¸€éƒ¨åˆ†ï¼ˆé€—å·åˆ†éš”ï¼‰
            param_first = param.split(",")[0] if param else ""
            # æ ¼å¼ï¼š[href, param, æ—¥æœŸ, è´Ÿè´£äºº, çŠ¶æ€]
            rows.append([href, param_first, today, "", ""])
        else:
            # æœªçŸ¥æ ¼å¼ï¼Œè·³è¿‡
            print(f"âš ï¸ è·³è¿‡æœªçŸ¥æ ¼å¼çš„æ•°æ®: {item}")
            continue

    return rows


def write_batch_to_sheets_with_retry(batch_results, batch_id, config, max_retries=3):
    """
    å¸¦é‡è¯•æœºåˆ¶çš„æ‰¹æ¬¡ç»“æœå†™å…¥Google Sheets
    """
    if not batch_results or not config:
        if batch_results:
            print(
                f"âš ï¸  ç¬¬ {batch_id} æ‰¹æ¬¡æœ‰ {len(batch_results)} ä¸ªç»“æœï¼Œä½†é…ç½®ç¼ºå¤±ï¼Œè·³è¿‡å†™å…¥"
            )
        return False

    print(
        f"ğŸ“ ç«‹å³å†™å…¥ç¬¬ {batch_id} æ‰¹æ¬¡çš„ {len(batch_results)} ä¸ªç»“æœåˆ°Google Sheets..."
    )

    retry_count = 0
    while retry_count < max_retries:
        try:
            sheets_config = config.get_sheets_config()
            write_google_sheets(
                parse_data(batch_results),
                sheets_config["credentials_path"],
                sheets_config["sheet_name"],
                sheets_config["worksheet_name"],
            )
            print(f"âœ… ç¬¬ {batch_id} æ‰¹æ¬¡ç»“æœå·²æˆåŠŸå†™å…¥Google Sheets")
            return True

        except Exception as e:
            retry_count += 1
            if retry_count < max_retries:
                print(
                    f"âš ï¸  ç¬¬ {batch_id} æ‰¹æ¬¡å†™å…¥å¤±è´¥ï¼Œç¬¬ {retry_count} æ¬¡é‡è¯•: {str(e)}"
                )
                import time

                time.sleep(2**retry_count)  # æŒ‡æ•°é€€é¿ï¼š2ç§’ã€4ç§’ã€8ç§’
            else:
                print(
                    f"âŒ ç¬¬ {batch_id} æ‰¹æ¬¡å†™å…¥Google Sheetså¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {str(e)}"
                )
                return False

    return False


def fetch_urls_batch(api_url, batch_size=50, skip=0, config=None):
    """
    è·å–ä¸€æ‰¹URL
    :param api_url: API URL
    :param batch_size: æ‰¹æ¬¡å¤§å°
    :param skip: è·³è¿‡çš„æ•°é‡
    :return: URLåˆ—è¡¨
    """
    print(f"ğŸ”— è°ƒç”¨API: {api_url}")
    end_date = f"{datetime.datetime.now().strftime('%Y-%m-%d')} 23:59:59"
    print(f"ç»“æŸæ—¥æœŸ: {end_date}")
    data = {
        "type": "json",
        "author": "admin",
        "begin_date": f"{(datetime.datetime.now() - datetime.timedelta(days=config.cache_date_len)).strftime('%Y-%m-%d')} 00:00:00",
        "end_date": f"{datetime.datetime.now().strftime('%Y-%m-%d')} 23:59:59",
        "top_n": batch_size,
        "meet_template": 1,
        "meet_fz": 1,
        "repeat_sent": 1,
        "filter_collect": 1,
        "urls": config.req_urls,
    }

    response = requests.post(api_url, json=data)
    try:
        res_data = response.json()
    except ValueError:
        return []
    # è¿½åŠ å†™å…¥åˆ°res_data.jsonæ–‡ä»¶
    file_name = f"log/res_data_{config.worksheet_name}_{datetime.datetime.now().strftime('%Y%m%d')}.json"
    try:
        # å°è¯•è¯»å–ç°æœ‰æ•°æ®
        with open(file_name, "r", encoding="utf-8") as f:
            existing_data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯ï¼Œåˆ›å»ºç©ºåˆ—è¡¨
        existing_data = []

    # ç¡®ä¿existing_dataæ˜¯åˆ—è¡¨
    if not isinstance(existing_data, list):
        existing_data = []

    # å°†æ–°æ•°æ®è¿½åŠ åˆ°ç°æœ‰æ•°æ®
    if isinstance(res_data, list):
        existing_data.extend(res_data)
    else:
        existing_data.append(res_data)

    # å†™å›æ–‡ä»¶
    with open(file_name, "w", encoding="utf-8") as f:
        f.write(json.dumps(existing_data, ensure_ascii=False, indent=4))
    res = [
        {
            "href": x.get("href"),
            "param": x.get("param", "").split(",")[0] if x.get("param") else "",
        }
        for x in res_data
        if isinstance(x, dict) and x.get("href")
    ]
    print(f"æ‰¹æ¬¡ {skip//batch_size + 1}: è·å–åˆ° {len(res)} ä¸ªURL")
    return res


def get_url(api_url, config=None):
    """
    è·å–URLå¹¶å¤„ç†è¡¨å•æ£€æŸ¥ï¼Œæ”¯æŒå¾ªç¯è·å–ç›´åˆ°æ»¡è¶³æœ€å°ç»“æœæ•°é‡
    :param api_url: API URL
    :param config: é…ç½®å¯¹è±¡ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    """
    print(f"å¼€å§‹å¤„ç†worksheet_name: {config.worksheet_name}")
    # è®¾ç½®é»˜è®¤é…ç½®
    min_results = URL_GROUPS.get(config.worksheet_name, {}).get(
        "min_results", config.min_results
    )
    batch_size = config.batch_size if config else 50
    max_batches = config.max_batches if config else 5
    max_urls = config.max_urls if config else None

    print(f"ç›®æ ‡ï¼šè·å–è‡³å°‘ {min_results} ä¸ªæœ‰æ•ˆç»“æœ")
    print(f"é…ç½®ï¼šæ‰¹æ¬¡å¤§å°={batch_size}, æœ€å¤§æ‰¹æ¬¡æ•°={max_batches}")

    all_valid_results = []  # å­˜å‚¨æ‰€æœ‰æœ‰æ•ˆç»“æœï¼ˆåŒ…å«å®Œæ•´æ•°æ®ï¼‰
    processed_urls = set()  # é¿å…é‡å¤å¤„ç†ç›¸åŒURL
    current_batch = 0
    skip = 0

    while len(all_valid_results) < min_results and current_batch < max_batches:
        current_batch += 1
        print(f"\n{'='*60}")
        print(f"ç¬¬ {current_batch} æ‰¹æ¬¡å¼€å§‹...")
        res_datas = fetch_urls_batch(api_url, batch_size, skip, config)

        if not res_datas:
            print(f"ç¬¬ {current_batch} æ‰¹æ¬¡æ²¡æœ‰è·å–åˆ°æ•°æ®ï¼Œåœæ­¢")
            continue

        # åˆ›å»ºURLåˆ°å®Œæ•´æ•°æ®çš„æ˜ å°„
        url_to_data = {item.get("href"): item for item in res_datas if item.get("href")}
        batch_urls = list(url_to_data.keys())

        if not batch_urls:
            print(f"ç¬¬ {current_batch} æ‰¹æ¬¡æ²¡æœ‰è·å–åˆ°æ–°URLï¼Œåœæ­¢")
            continue

        # è¿‡æ»¤æ‰å·²å¤„ç†çš„URL
        new_urls = [u for u in batch_urls if u not in processed_urls]
        if not new_urls:
            print(f"ç¬¬ {current_batch} æ‰¹æ¬¡æ²¡æœ‰æ–°URLï¼Œåœæ­¢")
            continue

        # é™åˆ¶URLæ•°é‡ï¼ˆå¦‚æœè®¾ç½®äº†max_urlsï¼‰
        if max_urls and len(processed_urls) + len(new_urls) > max_urls:
            new_urls = new_urls[: max_urls - len(processed_urls)]

        print(f"æ–°URLæ•°é‡: {len(new_urls)}")

        # æ ‡è®°ä¸ºå·²å¤„ç†
        processed_urls.update(new_urls)

        # æ£€æŸ¥è¿™æ‰¹URLä¸­çš„è¡¨å•ï¼ˆä½¿ç”¨å¤šé¡µé¢å¹¶è¡Œå¤„ç†ï¼‰
        print(f"å¼€å§‹æ£€æŸ¥ç¬¬ {current_batch} æ‰¹æ¬¡çš„ {len(new_urls)} ä¸ªURL...")
        # æ ¹æ®URLæ•°é‡åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°å’Œé¡µé¢æ•°
        max_concurrent = min(4, max(2, len(new_urls) // 15))
        pages_per_context = min(6, max(3, len(new_urls) // max_concurrent // 3))

        print(
            f"ğŸ”§ å¹¶è¡Œé…ç½®: {max_concurrent} ä¸Šä¸‹æ–‡ Ã— {pages_per_context} é¡µé¢ = {max_concurrent * pages_per_context} å¹¶è¡Œåº¦"
        )
        batch_results = asyncio.run(
            load_url(new_urls, max_concurrent, pages_per_context)
        )

        # å°†æ‰¾åˆ°è¡¨å•çš„URLè½¬æ¢ä¸ºå®Œæ•´æ•°æ®ï¼ˆåŒ…å«paramï¼‰
        batch_results_with_data = []
        for result_url in batch_results:
            if result_url in url_to_data:
                batch_results_with_data.append(url_to_data[result_url])
            else:
                # å¦‚æœæ²¡æ‰¾åˆ°å¯¹åº”æ•°æ®ï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬ç»“æ„
                batch_results_with_data.append({"href": result_url, "param": ""})

        # å®æ—¶å†™å…¥æœ¬æ‰¹æ¬¡çš„ç»“æœåˆ°Google Sheetsï¼ˆå¦‚æœå¯ç”¨ï¼‰
        write_success = True  # é»˜è®¤æˆåŠŸï¼Œå¦‚æœæ²¡æœ‰å¯ç”¨å®æ—¶å†™å…¥
        if config and config.realtime_write:
            write_success = write_batch_to_sheets_with_retry(
                batch_results_with_data, current_batch, config, config.write_retry
            )
        elif batch_results_with_data:
            print(
                f"ğŸ“‹ ç¬¬ {current_batch} æ‰¹æ¬¡æ‰¾åˆ° {len(batch_results_with_data)} ä¸ªç»“æœï¼ˆå®æ—¶å†™å…¥å·²ç¦ç”¨ï¼‰"
            )

        # æ·»åŠ åˆ°æ€»ç»“æœä¸­ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
        all_valid_results.extend(batch_results_with_data)

        print(f"ç¬¬ {current_batch} æ‰¹æ¬¡å®Œæˆ:")
        print(f"  - æ£€æŸ¥URLæ•°: {len(new_urls)}")
        print(f"  - æœ‰æ•ˆç»“æœ: {len(batch_results)}")
        print(f"  - ç´¯è®¡æœ‰æ•ˆç»“æœ: {len(all_valid_results)}")
        print(f"  - ç›®æ ‡è¿›åº¦: {len(all_valid_results)}/{min_results}")

        if config and config.realtime_write:
            if batch_results and write_success:
                print(f"  - âœ… æœ¬æ‰¹æ¬¡ç»“æœå·²å®æ—¶å†™å…¥Google Sheets")
            elif batch_results and not write_success:
                print(f"  - âŒ æœ¬æ‰¹æ¬¡ç»“æœå†™å…¥Google Sheetså¤±è´¥ï¼Œå·²ä¿å­˜æœ¬åœ°å¤‡ä»½")
        elif batch_results:
            print(f"  - ğŸ“‹ æœ¬æ‰¹æ¬¡ç»“æœå·²ç¼“å­˜ï¼Œå°†åœ¨æœ€åç»Ÿä¸€å†™å…¥")

        # å¦‚æœå·²è¾¾åˆ°ç›®æ ‡ï¼Œæå‰ç»“æŸ
        if len(all_valid_results) >= min_results:
            print(f"âœ… å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {min_results}ï¼Œåœæ­¢è·å–")
            break

        # å¦‚æœè®¾ç½®äº†max_urlsé™åˆ¶ä¸”å·²è¾¾åˆ°ï¼Œåœæ­¢
        if max_urls and len(processed_urls) >= max_urls:
            print(f"âœ… å·²è¾¾åˆ°æœ€å¤§URLé™åˆ¶ {max_urls}ï¼Œåœæ­¢è·å–")
            break

        # å‡†å¤‡ä¸‹ä¸€æ‰¹æ¬¡
        skip += batch_size

        # æ·»åŠ çŸ­æš‚å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
        import time

        time.sleep(1)

    print(f"\n{'='*60}")
    print(f"ğŸ¯ æœ€ç»ˆç»“æœ:")
    print(f"  - æ€»æ‰¹æ¬¡æ•°: {current_batch}")
    print(f"  - æ£€æŸ¥URLæ€»æ•°: {len(processed_urls)}")
    print(f"  - æœ‰æ•ˆç»“æœæ•°: {len(all_valid_results)}")
    print(
        f"  - ç›®æ ‡å®Œæˆåº¦: {len(all_valid_results)}/{min_results} ({len(all_valid_results)/min_results*100:.1f}%)"
    )

    # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦éœ€è¦æœ€ç»ˆå†™å…¥
    if config and config.realtime_write:
        # å®æ—¶å†™å…¥æ¨¡å¼ï¼šç»“æœå·²ç»åœ¨æ¯æ‰¹æ¬¡å®Œæˆåå†™å…¥
        if all_valid_results:
            print(f"âœ… æ‰€æœ‰ {len(all_valid_results)} ä¸ªç»“æœå·²å®æ—¶å†™å…¥Google Sheets")
        else:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆç»“æœ")
    else:
        # æ‰¹é‡å†™å…¥æ¨¡å¼ï¼šåœ¨æœ€åç»Ÿä¸€å†™å…¥æ‰€æœ‰ç»“æœ
        if all_valid_results:
            print(f"ğŸ“ å¼€å§‹å†™å…¥æ‰€æœ‰ {len(all_valid_results)} ä¸ªç»“æœåˆ°Google Sheets...")
            try:
                if config:
                    sheets_config = config.get_sheets_config()
                    write_google_sheets(
                        parse_data(all_valid_results),
                        sheets_config["credentials_path"],
                        sheets_config["sheet_name"],
                        sheets_config["worksheet_name"],
                    )
                else:
                    write_google_sheets(parse_data(all_valid_results))
                print(f"âœ… æ‰€æœ‰ {len(all_valid_results)} ä¸ªç»“æœå·²æˆåŠŸå†™å…¥Google Sheets")
            except Exception as e:
                print(f"âŒ æ‰¹é‡å†™å…¥Google Sheetså¤±è´¥: {str(e)}")

        else:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆç»“æœ")

    # æ”¶é›†å½“å‰å·¥ä½œè¡¨çš„ç»Ÿè®¡ä¿¡æ¯
    if config and hasattr(config, "worksheet_name"):
        current_ws = config.worksheet_name
        WORKSHEET_STATS[current_ws] = {
            "worksheet_name": current_ws,
            "target_results": min_results,
            "actual_results": len(all_valid_results),
            "total_batches": current_batch,
            "completion_rate": (
                round((len(all_valid_results) / min_results) * 100, 1)
                if min_results > 0
                else 0
            ),
            "status": (
                "âœ… å®Œæˆ" if len(all_valid_results) >= min_results else "âš ï¸ æœªè¾¾æ ‡"
            ),
        }

    # æ£€æŸ¥æ˜¯å¦æ˜¯æ‰‹åŠ¨æŒ‡å®šçš„å•ä¸ªå·¥ä½œè¡¨æ‰§è¡Œ
    if (
        config
        and hasattr(config, "run_single_worksheet")
        and config.run_single_worksheet
    ):
        # æ‰‹åŠ¨æŒ‡å®šå•ä¸ªå·¥ä½œè¡¨ï¼Œç›´æ¥ç»“æŸï¼Œä¸è¿›è¡Œåºåˆ—å¤„ç†
        print(f"âœ… æ‰‹åŠ¨æ‰§è¡Œå·¥ä½œè¡¨ '{config.worksheet_name}' å®Œæˆ")
        return all_valid_results

    # æŒ‰é¡ºåºä¾æ¬¡æ‰§è¡Œ [00, p0, p1]
    if config:
        sequence = ["00", "p0", "p1"]
        current_ws = getattr(config, "worksheet_name", None)
        if current_ws in sequence:
            if current_ws == sequence[-1]:
                # æœ€åä¸€ä¸ªå·¥ä½œè¡¨å®Œæˆï¼Œå‘é€æ±‡æ€»æŠ¥å‘Š
                send_summary_report()
                return all_valid_results
            # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª worksheet
            next_index = sequence.index(current_ws) + 1
            next_ws = sequence[next_index]
            # æ›´æ–°é…ç½®ä¸­çš„ç›®æ ‡ worksheet åŠå…¶ç›¸å…³å‚æ•°
            config.worksheet_name = next_ws
            config.req_urls = URL_GROUPS.get(next_ws, {}).get("urls", "")
            # è‹¥æœ‰ä¸ºä¸åŒè¡¨å®šä¹‰çš„æœ€å°ç»“æœé˜ˆå€¼ï¼Œåˆ™åŒæ­¥æ›´æ–°
            config.min_results = URL_GROUPS.get(next_ws, {}).get(
                "min_results", config.min_results
            )
            # é€’å½’è°ƒç”¨å¤„ç†ä¸‹ä¸€ä¸ªå·¥ä½œè¡¨
            get_url(API_URL, config)
        else:
            # æœªè¯†åˆ«çš„ worksheetï¼Œç›´æ¥ç»“æŸ
            return all_valid_results
    else:
        # æ— é…ç½®å¯¹è±¡ï¼Œæ— æ³•ä¸²è¡Œè°ƒåº¦ï¼Œç›´æ¥ç»“æŸ
        return all_valid_results


if __name__ == "__main__":
    from config import Config

    # ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®ç®¡ç†
    config = Config()

    api_url = "http://testing-novabid-dsp.testing.svc.gzk8s.zhizh.com/api/admin/script/export/filter"
    get_url(api_url, config)
